{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, asdict\n",
    "from hyperopt import fmin, tpe, hp, space_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '~/Desktop/final'\n",
    "train_origin = pd.read_csv(dir_path + '/train_final.csv', engine='python')\n",
    "test_origin = pd.read_csv(dir_path + '/test_final.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_ENCODING_MAP = {}\n",
    "\n",
    "def get_kfold_target_encoding(data, col_prefix, label, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits)\n",
    "    col_list = [col for col in data.columns if col.startswith(col_prefix)]\n",
    "    col_map = {col:{'count':0, 'value':0, 'weight':0} for col in col_list}\n",
    "    for other_id, current_id in kfold.split(data):\n",
    "        current_df = data.loc[current_id]\n",
    "        other_df = data.loc[other_id]\n",
    "        for col_name in col_list:\n",
    "            x_sum = len(other_df[other_df[col_name] == 1])\n",
    "            y_sum = float(other_df[other_df[col_name] == 1][label].sum())\n",
    "            x_count = len(current_df[current_df[col_name] == 1])\n",
    "            col_map[col_name]['count'] += x_count\n",
    "            col_map[col_name]['value'] += x_count * y_sum / x_sum\n",
    "    \n",
    "    for k in col_map:\n",
    "        col_map[k]['weight'] = col_map[k]['value'] / col_map[k]['count']\n",
    "    return col_map\n",
    "\n",
    "\n",
    "def append_target_encoding(data, col_prefix, label, drop=True):\n",
    "    def get_feature_value(x, col_list, col_map):\n",
    "        val_list = [x[i] for i in col_list]\n",
    "        return col_map[col_list[val_list.index(1)]]['weight']\n",
    "    \n",
    "    if col_prefix not in TARGET_ENCODING_MAP:\n",
    "        col_map = get_kfold_target_encoding(data, col_prefix, label)\n",
    "        TARGET_ENCODING_MAP[col_prefix] = col_map\n",
    "    else:\n",
    "        col_map = TARGET_ENCODING_MAP[col_prefix]\n",
    "    \n",
    "    col_list = [col for col in data.columns if col_prefix in col] \n",
    "    new_col = 'new_' + col_prefix + '_target_encoding'\n",
    "    \n",
    "    data[new_col] = data.apply(lambda x: get_feature_value(x, col_list, col_map), axis=1)\n",
    "    if drop:\n",
    "        data.drop(columns=col_list, inplace=True)\n",
    "        \n",
    "\n",
    "def process_data(data_origin, label, flag):\n",
    "    data = data_origin.copy()\n",
    "    if flag:\n",
    "        data['r01'] = data['discrete_emp_length_12_one_hot']\n",
    "        data['r02'] = data['discrete_emp_length_5_one_hot']\n",
    "        data['r03'] = data['discrete_emp_length_7_one_hot']\n",
    "        data['r04'] = data['discrete_addr_state_37_one_hot'] \n",
    "        data['r05'] = data['discrete_addr_state_43_one_hot']\n",
    "        data['r06'] = data['discrete_addr_state_8_one_hot']\n",
    "        data['r07'] = data['discrete_addr_state_25_one_hot']\n",
    "        data['r08'] = data['discrete_addr_state_4_one_hot']\n",
    "        data['r09'] = data['discrete_addr_state_15_one_hot']\n",
    "        data['r10'] = data['discrete_addr_state_23_one_hot']\n",
    "        data['r11'] = data['discrete_addr_state_12_one_hot']\n",
    "        data['r12'] = data['discrete_addr_state_6_one_hot']\n",
    "        data['r13'] = data['discrete_grade_2_one_hot']\n",
    "        data['r14'] = data['discrete_sub_grade_13_one_hot']\n",
    "        data['r15'] = data['discrete_sub_grade_4_one_hot']\n",
    "        data['r16'] = data['discrete_sub_grade_6_one_hot']\n",
    "        data['r17'] = data['discrete_purpose_6_one_hot']\n",
    "\n",
    "        append_target_encoding(data, 'discrete_grade', label, True)\n",
    "        append_target_encoding(data, 'discrete_sub_grade', label, True)\n",
    "        append_target_encoding(data, 'discrete_purpose', label, True)\n",
    "        append_target_encoding(data, 'discrete_emp_length', label, True)\n",
    "        append_target_encoding(data, 'discrete_addr_state', label, True)\n",
    "    \n",
    "#     data['d1'] = data['continuous_installment'] / (data['continuous_annual_inc']/12)\n",
    "#     data['d2'] = data['d1'] * data['continuous_dti']\n",
    "#     data['d3'] = data['d1'] * data['continuous_int_rate']\n",
    "#     data['d4'] = data['continuous_loan_amnt'] / data['continuous_funded_amnt']\n",
    "#     data['d5'] = data['continuous_annual_inc'] / data['continuous_annual_inc_joint']\n",
    "#     data['d6'] = data['continuous_dti'] * data['continuous_dti_joint']\n",
    "    \n",
    "#     data['k1'] = data['continuous_mths_since_last_record'] / data['continuous_mths_since_last_delinq']\n",
    "#     data['k2'] = data['k1'] * data['continuous_inq_last_6mths']\n",
    "    \n",
    "#     data['t1'] = data['continuous_fico_range_high'] - data['continuous_last_fico_range_high']\n",
    "#     data['t2'] = data['continuous_fico_range_high'] + data['continuous_last_fico_range_high']\n",
    "    \n",
    "#     data['w1'] = data['new_discrete_purpose_target_encoding'] * data['new_discrete_addr_state_target_encoding']\n",
    "#     data['w2'] = data['new_discrete_emp_length_target_encoding'] * data['continuous_pub_rec']\n",
    "    \n",
    "#     data.drop(columns = ['discrete_policy_code_1_one_hot',\n",
    "#                          'discrete_pymnt_plan_1_one_hot',\n",
    "#                         ], inplace=True)\n",
    "    \n",
    "#    return data.sample(frac=1).reset_index().drop(columns='index')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LGBOpt:\n",
    "    num_thread: any = hp.choice('num_thread', [6])    # cpu_count\n",
    "    num_leaves: any = hp.choice('num_leaves', [4, 8, 16, 20, 24, 32, 40, 48, 56, 64])\n",
    "    metric: any = hp.choice('metric', ['binary'])\n",
    "    num_round: any = hp.choice('num_round', [2000])\n",
    "    objective: any = hp.choice('objective', ['binary'])\n",
    "    learning_rate: any = hp.uniform('learning_rate', 0.01, 0.1)\n",
    "    feature_fraction: any = hp.uniform('feature_fraction', 0.5, 1.0)\n",
    "    bagging_fraction: any = hp.uniform('bagging_fraction', 0.8, 1.0)\n",
    "    device_type: any = hp.choice('device_type',['cpu'])  # hp.choice('device_tpye', ['gpu']) \n",
    "    boosting: any = hp.choice('boosting', ['gbdt', 'dart', 'goss'])\n",
    "    extra_trees: any = hp.choice('extra_tress', [False, True])\n",
    "    drop_rate: any = hp.uniform('drop_rate', 0, 0.2)\n",
    "    uniform_drop: any = hp.choice('uniform_drop', [True, False])\n",
    "    lambda_l1: any = hp.uniform('lambda_l1', 0, 10)  # TODO: Check range\n",
    "    lambda_l2: any = hp.uniform('lambda_l2', 0, 10)  # TODO: Check range\n",
    "    min_gain_to_split: any = hp.uniform('min_gain_to_split', 0, 1)  # TODO: Check range\n",
    "    min_data_in_bin: any = hp.choice('min_data_in_bin', [3, 5, 7, 10, 15, 20, 25, 30, 40, 50])\n",
    "    #max_depth: any = hp.choice('max_depth', [3, 4, 5, 6, 7, 8])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_common_params():\n",
    "        return {\n",
    "            'num_thread': 4, \n",
    "            'num_leaves': 12, \n",
    "            'metric': 'binary', \n",
    "            'objective': 'binary',\n",
    "            'num_round': 1000, \n",
    "            'learning_rate': 0.01, \n",
    "            'feature_fraction': 0.8, \n",
    "            'bagging_fraction': 0.8,\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitterBase(object):\n",
    "    def __init__(self, label, metric, max_eval=100, opt=None):\n",
    "        self.label = label\n",
    "        self.metric = metric\n",
    "        self.opt_params = dict()\n",
    "        self.max_eval = max_eval\n",
    "        self.opt = opt\n",
    "\n",
    "    def get_loss(self, y, y_pred):\n",
    "        if self.metric == 'error':\n",
    "            return 1 - accuracy_score(y, y_pred)\n",
    "        elif self.metric == 'precision':\n",
    "            return 1 - precision_score(y, y_pred)\n",
    "        elif self.metric == 'recall':\n",
    "            return 1 - recall_score(y, y_pred)\n",
    "        elif self.metric == 'macro_f1':\n",
    "            return 1 - f1_score(y, y_pred, average='macro')\n",
    "        elif self.metric == 'micro_f1':\n",
    "            return 1 - f1_score(y, y_pred, average='micro')\n",
    "        elif self.metric == 'auc':  # TODO: Add a warning checking if y_predict is all [0, 1], it should be probability\n",
    "            return 1 - roc_auc_score(y, y_pred)\n",
    "        else:\n",
    "            raise Exception(\"Not implemented yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGBFitter(FitterBase):\n",
    "    \n",
    "    def __init__(self, label='label', metric='error', opt: LGBOpt = None, max_eval=100):\n",
    "        super(LGBFitter, self).__init__(label, metric, max_eval)\n",
    "        if opt is not None:\n",
    "            self.opt = opt\n",
    "        else:\n",
    "            self.opt = LGBOpt()\n",
    "        self.best_round = None\n",
    "        self.clf = None\n",
    "\n",
    "        \n",
    "    def train(self, train_df, eval_df, params=None, use_best_eval=True):\n",
    "        # 训练前清空 self.best_round\n",
    "        self.best_round = None\n",
    "        dtrain = lgb.Dataset(train_df.drop(columns=[self.label]), train_df[self.label])\n",
    "        deval = lgb.Dataset(eval_df.drop(columns=[self.label]), eval_df[self.label])\n",
    "        evallist = [dtrain, deval]\n",
    "        # 若 params 参数为空， 则使用 opt 搜索的参数\n",
    "        if params is None:\n",
    "            use_params = deepcopy(self.opt_params)\n",
    "        else:\n",
    "            use_params = deepcopy(params)\n",
    "\n",
    "        num_round = use_params.pop('num_round')\n",
    "        # 默认使用 self.best_round 为最小错误率的轮数\n",
    "        if use_best_eval:\n",
    "            with io.StringIO() as buf, redirect_stdout(buf):\n",
    "                self.clf = lgb.train(use_params, dtrain, num_round, valid_sets=evallist)\n",
    "                output = buf.getvalue().split(\"\\n\")\n",
    "            min_error = np.inf\n",
    "            min_index = 0\n",
    "            for idx in range(len(output) - 1):\n",
    "                if len(output[idx].split(\"\\t\")) == 3:\n",
    "                    temp = float(output[idx].split(\"\\t\")[2].split(\":\")[1])\n",
    "                    if min_error > temp:\n",
    "                        min_error = temp\n",
    "                        min_index = int(output[idx].split(\"\\t\")[0][1:-1])\n",
    "            print(\"The minimum is attained in round %d\" % (min_index + 1))\n",
    "            self.best_round = min_index + 1\n",
    "            return output\n",
    "        else:\n",
    "            with io.StringIO() as buf, redirect_stdout(buf):\n",
    "                self.clf = lgb.train(use_params, dtrain, num_round, valid_sets=evallist)\n",
    "                output = buf.getvalue().split(\"\\n\")\n",
    "            self.best_round = num_round\n",
    "            return output\n",
    "\n",
    "        \n",
    "    # 单模型搜索 self.opt_params\n",
    "    def search(self, train_df, eval_df, use_best_eval=True):\n",
    "        self.opt_params = dict()\n",
    "\n",
    "        def train_impl(params):\n",
    "            self.train(train_df, eval_df, params, use_best_eval)\n",
    "            if self.metric == 'auc':\n",
    "                y_pred = self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round)\n",
    "            else:\n",
    "                y_pred = (self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round) > 0.5).astype(int)  \n",
    "            return self.get_loss(eval_df[self.label], y_pred)\n",
    "        \n",
    "        argmin_params = fmin(train_impl, asdict(self.opt), algo=tpe.suggest, max_evals=self.max_eval)\n",
    "        self.opt_params = space_eval(asdict(self.opt), argmin_params)\n",
    "\n",
    "        \n",
    "    # k-fold模型搜索 self.opt_params\n",
    "    def search_k_fold(self, k_fold, data, use_best_eval=True):\n",
    "        self.opt_params = dict()\n",
    "\n",
    "        def train_impl_nfold(params):\n",
    "            loss = list()\n",
    "            for train_id, eval_id in k_fold.split(data):\n",
    "                train_df = data.loc[train_id]\n",
    "                eval_df = data.loc[eval_id]\n",
    "                self.train(train_df, eval_df, params, use_best_eval)\n",
    "                if self.metric == 'auc':\n",
    "                    y_pred = self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round)\n",
    "                else:\n",
    "                    y_pred = (self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round) > 0.5).astype(int)\n",
    "                loss.append(self.get_loss(eval_df[self.label], y_pred))\n",
    "            return np.mean(loss)\n",
    "\n",
    "        argmin_params = fmin(train_impl_nfold, asdict(self.opt), algo=tpe.suggest, max_evals=self.max_eval)\n",
    "        self.opt_params = space_eval(asdict(self.opt), argmin_params)\n",
    "        \n",
    "        \n",
    "    def train_k_fold(self, k_fold, train_data, test_data, params=None, drop_test_y=True, use_best_eval=True):\n",
    "        acc_result = list()\n",
    "        train_pred = np.empty(train_data.shape[0])\n",
    "        test_pred = np.empty(test_data.shape[0])\n",
    "        test_pred_list = list()\n",
    "        models = list()\n",
    "        \n",
    "        if drop_test_y:\n",
    "            dtest = test_data.drop(columns=self.label)\n",
    "        else:\n",
    "            dtest = test_data\n",
    "\n",
    "        for train_id, eval_id in k_fold.split(train_data):\n",
    "            train_df = train_data.loc[train_id]\n",
    "            eval_df = train_data.loc[eval_id]\n",
    "            self.train(train_df, eval_df, params, use_best_eval)\n",
    "            models.append(deepcopy(self.clf))\n",
    "            train_pred[eval_id] = self.clf.predict(eval_df.drop(columns=self.label), num_iteration=self.best_round)\n",
    "            if self.metric == 'auc':\n",
    "                y_pred = self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round)\n",
    "            else:\n",
    "                y_pred = (self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round) > 0.5).astype(int)\n",
    "            acc_result.append(self.get_loss(eval_df[self.label], y_pred))\n",
    "            new_test_pred = self.clf.predict(dtest, num_iteration=self.best_round)\n",
    "            test_pred += new_test_pred\n",
    "            test_pred_list.append(new_test_pred)\n",
    "        \n",
    "        test_pred /= k_fold.n_splits\n",
    "        \n",
    "        if self.metric != 'auc':\n",
    "            train_pred = (train_pred > 0.5).astype(int)\n",
    "            test_pred = (test_pred > 0.5).astype(int)\n",
    "        test_acc = self.get_loss(test_data[self.label], test_pred)\n",
    "        \n",
    "        return {\n",
    "            'models'     : models,\n",
    "            'train_pred' : train_pred,\n",
    "            'test_pred'  : test_pred,\n",
    "            'acc_result' : [round(i, 5) for i in acc_result],\n",
    "            'acc_result_mean' : round(np.mean([round(i, 5) for i in acc_result]), 5),\n",
    "            'test_pred_list'    : test_pred_list,\n",
    "            'test_acc'   : round(test_acc, 5),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = LGBFitter(label='loan_status')\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitter.search_k_fold(kfold, train, use_best_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitter.opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第1次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum is attained in round 487\n",
      "Finished loading model, total used 2000 iterations\n",
      "The minimum is attained in round 322\n",
      "Finished loading model, total used 2000 iterations\n",
      "The minimum is attained in round 444\n",
      "Finished loading model, total used 2000 iterations\n",
      "The minimum is attained in round 495\n",
      "Finished loading model, total used 2000 iterations\n",
      "The minimum is attained in round 625\n",
      "Finished loading model, total used 2000 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0719, 0.0814, 0.0829, 0.0822, 0.0776], 0.0792, 0.08176)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = {'bagging_fraction': 0.9379122665132016,\n",
    " 'boosting': 'goss',\n",
    " 'device_type': 'cpu',\n",
    " 'drop_rate': 0.0003757191912043406,\n",
    " 'extra_trees': True,\n",
    " 'feature_fraction': 0.7837989424839368,\n",
    " 'lambda_l1': 2.4791237795383174,\n",
    " 'lambda_l2': 5.423097004780251,\n",
    " 'learning_rate': 0.027638820456068754,\n",
    " 'metric': 'binary',\n",
    " 'min_data_in_bin': 20,\n",
    " 'min_gain_to_split': 0.9418873172596369,\n",
    " 'num_leaves': 64,\n",
    " 'num_round': 2000,\n",
    " 'num_thread': 6,\n",
    " 'objective': 'binary',\n",
    " 'uniform_drop': False}\n",
    "\n",
    "train = process_data(train_origin, 'loan_status', False)\n",
    "test = process_data(test_origin, 'loan_status', False)\n",
    "data = pd.concat([train, test], axis=0)\n",
    "result_map = fitter.train_k_fold(kfold, train, test, params = p1)\n",
    "result_map['acc_result'], result_map['acc_result_mean'], result_map['test_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第2次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum is attained in round 331\n",
      "Finished loading model, total used 613 iterations\n",
      "The minimum is attained in round 710\n",
      "Finished loading model, total used 626 iterations\n",
      "The minimum is attained in round 1876\n",
      "Finished loading model, total used 563 iterations\n",
      "The minimum is attained in round 1977\n",
      "Finished loading model, total used 620 iterations\n",
      "The minimum is attained in round 353\n",
      "Finished loading model, total used 629 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0706, 0.0803, 0.0827, 0.0828, 0.0778], 0.07884, 0.08166)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = {'bagging_fraction': 0.8820761355932795,\n",
    " 'boosting': 'gbdt',\n",
    " 'device_type': 'cpu',\n",
    " 'drop_rate': 0.15221361387442056,\n",
    " 'extra_trees': True,\n",
    " 'feature_fraction': 0.7966085155023439,\n",
    " 'lambda_l1': 9.05999616675501,\n",
    " 'lambda_l2': 2.514529861096307,\n",
    " 'learning_rate': 0.09924903847628047,\n",
    " 'metric': 'binary',\n",
    " 'min_data_in_bin': 5,\n",
    " 'min_gain_to_split': 0.06684328574175302,\n",
    " 'num_leaves': 8,\n",
    " 'num_round': 2000,\n",
    " 'num_thread': 6,\n",
    " 'objective': 'binary',\n",
    " 'uniform_drop': False}\n",
    "\n",
    "train = process_data(train_origin, 'loan_status', True)\n",
    "test = process_data(test_origin, 'loan_status', True)\n",
    "data = pd.concat([train, test], axis=0)\n",
    "result_map = fitter.train_k_fold(kfold, train, test, params = p2)\n",
    "result_map['acc_result'], result_map['acc_result_mean'], result_map['test_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第3次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum is attained in round 687\n",
      "Finished loading model, total used 2000 iterations\n",
      "The minimum is attained in round 649\n",
      "Finished loading model, total used 1999 iterations\n",
      "The minimum is attained in round 487\n",
      "Finished loading model, total used 1999 iterations\n",
      "The minimum is attained in round 1612\n",
      "Finished loading model, total used 2000 iterations\n",
      "The minimum is attained in round 407\n",
      "Finished loading model, total used 2000 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0709, 0.0791, 0.0829, 0.084, 0.0789], 0.07916, 0.08148)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3 =  {'bagging_fraction': 0.8470798531544796,\n",
    " 'boosting': 'goss',\n",
    " 'device_type': 'cpu',\n",
    " 'drop_rate': 0.04362493523196063,\n",
    " 'extra_trees': True,\n",
    " 'feature_fraction': 0.8416459394914348,\n",
    " 'lambda_l1': 5.246746455101715,\n",
    " 'lambda_l2': 5.4885609875994685,\n",
    " 'learning_rate': 0.0361569056025585,\n",
    " 'metric': 'binary',\n",
    " 'min_data_in_bin': 30,\n",
    " 'min_gain_to_split': 0.265040733262803,\n",
    " 'num_leaves': 24,\n",
    " 'num_round': 2000,\n",
    " 'num_thread': 6,\n",
    " 'objective': 'binary',\n",
    " 'uniform_drop': True}\n",
    "\n",
    "train = process_data(train_origin, 'loan_status', True)\n",
    "test = process_data(test_origin, 'loan_status', True)\n",
    "data = pd.concat([train, test], axis=0)\n",
    "result_map = fitter.train_k_fold(kfold, train, test, params = p3)\n",
    "result_map['acc_result'], result_map['acc_result_mean'], result_map['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 观察特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\n",
    "#         'column': train.drop(columns='loan_status').columns,\n",
    "#         'importance': result_map['models'][0].feature_importance(),\n",
    "# }).sort_values(by='importance', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "调参方式： 统一采用 K-fold 的 hyperopt 调参， 使用”分类错误率“衡量结果\n",
    "\n",
    "第一次测试： （使用原始数据，无任何衍生变量)\n",
    "\n",
    "    训练数据结果： \n",
    "    Kfold 错误率：[0.0719, 0.0814, 0.0829, 0.0822, 0.0776]  错误率均值：0.07920\n",
    "    测试集效果：  0.08176\n",
    "    \n",
    "\n",
    "\n",
    "第二次测试：  构造衍生变量（kfold target encoding）\n",
    "\n",
    "    训练数据结果： \n",
    "    Kfold 错误率：[0.0706, 0.0803, 0.0827, 0.0828, 0.0778]   错误率均值：0.07884\n",
    "    测试集效果：  0.08166\n",
    "\n",
    "\n",
    "第三次测试：  保持衍生变量，调参减少过拟合\n",
    "\n",
    "    训练数据结果： \n",
    "    Kfold 错误率：[0.0709, 0.0791, 0.0829, 0.084, 0.0789]   错误率均值：0.07916\n",
    "    测试集效果：  0.08148\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "参数记录<br>\n",
    "第一次测试参数<br>\n",
    "\n",
    "`{'bagging_fraction': 0.9379122665132016,\n",
    " 'boosting': 'goss',\n",
    " 'device_type': 'cpu',\n",
    " 'drop_rate': 0.0003757191912043406,\n",
    " 'extra_trees': True,\n",
    " 'feature_fraction': 0.7837989424839368,\n",
    " 'lambda_l1': 2.4791237795383174,\n",
    " 'lambda_l2': 5.423097004780251,\n",
    " 'learning_rate': 0.027638820456068754,\n",
    " 'metric': 'binary',\n",
    " 'min_data_in_bin': 20,\n",
    " 'min_gain_to_split': 0.9418873172596369,\n",
    " 'num_leaves': 64,\n",
    " 'num_round': 2000,\n",
    " 'num_thread': 6,\n",
    " 'objective': 'binary',\n",
    " 'uniform_drop': False}`\n",
    " \n",
    "第二次测试参数<br>\n",
    " `{'bagging_fraction': 0.8820761355932795,\n",
    " 'boosting': 'gbdt',\n",
    " 'device_type': 'cpu',\n",
    " 'drop_rate': 0.15221361387442056,\n",
    " 'extra_trees': True,\n",
    " 'feature_fraction': 0.7966085155023439,\n",
    " 'lambda_l1': 9.05999616675501,\n",
    " 'lambda_l2': 2.514529861096307,\n",
    " 'learning_rate': 0.09924903847628047,\n",
    " 'metric': 'binary',\n",
    " 'min_data_in_bin': 5,\n",
    " 'min_gain_to_split': 0.06684328574175302,\n",
    " 'num_leaves': 8,\n",
    " 'num_round': 2000,\n",
    " 'num_thread': 6,\n",
    " 'objective': 'binary',\n",
    " 'uniform_drop': False}`\n",
    " \n",
    "第三次测试参数<br>\n",
    " `{'bagging_fraction': 0.8470798531544796,\n",
    " 'boosting': 'goss',\n",
    " 'device_type': 'cpu',\n",
    " 'drop_rate': 0.04362493523196063,\n",
    " 'extra_trees': True,\n",
    " 'feature_fraction': 0.8416459394914348,\n",
    " 'lambda_l1': 5.246746455101715,\n",
    " 'lambda_l2': 5.4885609875994685,\n",
    " 'learning_rate': 0.0361569056025585,\n",
    " 'metric': 'binary',\n",
    " 'min_data_in_bin': 30,\n",
    " 'min_gain_to_split': 0.265040733262803,\n",
    " 'num_leaves': 24,\n",
    " 'num_round': 2000,\n",
    " 'num_thread': 6,\n",
    " 'objective': 'binary',\n",
    " 'uniform_drop': True}`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37_ml]",
   "language": "python",
   "name": "conda-env-py37_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
